# Neural Grain Processor - Complete Pipeline Instructions

## Overview
This project implements a neural audio processor that learns to control spectral texture/grain in audio files using the CAK (Conditioning-Aware Kernels) architecture.

## Prerequisites
```bash
pip install torch librosa soundfile matplotlib tqdm numpy scipy
```

## Step-by-Step Instructions

### Step 1: Organize Your Audio Dataset 📁
Create the following folder structure and place your WAV files:
```
Drone/
├── Static/
└── Evolving/
Harmonic Progression/
```

### Step 2: Measure Grain (Spectral Flatness) 📊
```bash
python3 measure_audio_grain.py
```
**What it does:**
- Analyzes all WAV files in your folders
- Computes spectral flatness (objective grain measure)
- Creates `metadata.json` with grain values for each file
- Grain values typically range from 0.000000 to 0.061106

### Step 3: Generate Spectrograms 🎨
```bash
python3 convert_to_spectrograms.py
```
**What it does:**
- Converts each audio file to mel-spectrograms (128×256)
- Saves numpy arrays in `spectrograms/arrays/`
- Saves PNG visualizations in `spectrograms/images/`
- Creates `training_pairs.json` linking spectrograms to grain values

### Step 4: Train the CAK Grain Processor 🤖
```bash
python3 cak_grain_processor.py
```
**What it does:**
- Loads natural grain pairs from your dataset
- Trains neural network to transform low-grain → high-grain audio
- Uses bidirectional violation for accountability
- Runs for 100 epochs (~10-15 minutes on GPU/MPS)
- Saves trained model to `grain_processor_v2_output/`

**Expected output:**
- Training visualizations every 10 epochs
- Final model checkpoint
- Training history plots

### Step 5: Use the Neural Audio Processor 🎛️
```bash
python3 neural_audio_processor.py
```
**What it does:**
- Opens GUI interface
- Load any audio file
- Control grain with slider:
  - **-3 to -1**: Add texture/complexity
  - **0**: No change
  - **+1 to +3**: Smooth/simplify
- View before/after spectrograms
- Save processed audio

## File Structure

### Essential Files to Keep:
```
gloame.ai/
├── measure_audio_grain.py         # Step 2: Grain measurement
├── convert_to_spectrograms.py     # Step 3: Create spectrograms
├── cak_grain_processor.py         # Step 4: Train model
├── neural_audio_processor.py      # Step 5: Use model
├── metadata.json                  # Grain measurements
├── training_pairs.json           # Training data links
├── spectrograms/                 # Generated spectrograms
│   ├── arrays/                   # Numpy files
│   └── images/                   # PNG visualizations
├── grain_processor_v2_output/    # Trained model
│   ├── final_grain_processor_v2.pt
│   ├── samples/                  # Training visualizations
│   └── checkpoints/              # Training checkpoints
└── [Your Audio Folders]/         # Original audio files
```

### Files to Delete (if present):
- `grain_synth_gan.py` - First GAN attempt (superseded)
- `test_extreme_grain.py` - Testing script (no longer needed)
- `simple_audio_test.py` - CLI version (replaced by GUI)
- `gan_output/` - Old GAN output folder

## Understanding the Results

### What the Model Learned:
- **Negative grain values (-3 to 0)**: Add spectral complexity/texture
- **Positive grain values (0 to +3)**: Remove spectral complexity (smooth)
- The model learned YOUR music's specific texture patterns

### Key Innovation:
This system demonstrates that neural networks can:
1. Learn perceptual qualities from examples
2. Apply learned transformations to any audio
3. Provide intuitive control over complex audio attributes

## Troubleshooting

### If training doesn't converge:
- Ensure you have at least 50+ audio files
- Check that files have varying grain levels
- Try reducing batch size if memory issues

### If GUI has issues:
- Make sure tkinter is installed: `python3 -m tkinter`
- On macOS: `brew install python-tk`

### If processed audio sounds distorted:
- Try moderate grain values (-1.5 to +1.5)
- Extreme values (±3) can be too aggressive

## Next Steps

1. **Experiment with different audio**:
   - Try processing various genres
   - Test on speech, instruments, etc.

2. **Train on different attributes**:
   - Modify to learn reverb, compression, etc.
   - Need paired examples (dry/wet)

3. **Combine multiple attributes**:
   - Extend CAK to control multiple parameters
   - Create complex audio transformations

## Credits
Based on Austin Rockman's CAK (Conditioning-Aware Kernels) architecture for neural audio synthesis.